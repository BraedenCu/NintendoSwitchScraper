{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vexaiObjDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQtIHa1WT9xD5wqgHIlP1h",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BraedenCu/NintendoSwitchScraper/blob/master/vexaiObjDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcDdt-klRWzl"
      },
      "source": [
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import pycocotools\n",
        "import os\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import transforms as T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4aaytd0_Ugy"
      },
      "source": [
        "!git clone https://github.com/experiencor/raccoon_dataset.git\n",
        "!pwd\n",
        "labels = pd.read_csv(\"/content/raccoon_dataset/data/raccoon_labels.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ioRySI_CwI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d58a5c1-24d9-4238-9ee6-afcba5e75ab7"
      },
      "source": [
        "!git clone https://github.com/pytorch/vision.git\n",
        "!cd vision\n",
        "!cp /content/vision/references/detection/utils.py ../\n",
        "!cp /content/vision/references/detection/transforms.py ../\n",
        "!cp /content/vision/references/detection/coco_eval.py ../\n",
        "!cp /content/vision/references/detection/engine.py ../\n",
        "!cp /content/vision/references/detection/coco_utils.py ../\n",
        "%cd ../.."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'vision'...\n",
            "remote: Enumerating objects: 22445, done.\u001b[K\n",
            "remote: Counting objects: 100% (3226/3226), done.\u001b[K\n",
            "remote: Compressing objects: 100% (803/803), done.\u001b[K\n",
            "remote: Total 22445 (delta 2471), reused 3038 (delta 2343), pack-reused 19219\u001b[K\n",
            "Receiving objects: 100% (22445/22445), 27.08 MiB | 21.00 MiB/s, done.\n",
            "Resolving deltas: 100% (16530/16530), done.\n",
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrCZQCyTEtSA"
      },
      "source": [
        "def parse_one_annot(path_to_data_file, filename):\n",
        "   data = pd.read_csv(path_to_data_file)\n",
        "   boxes_array = data[data[\"filename\"] == filename][[\"xmin\", \"ymin\",        \n",
        "   \"xmax\", \"ymax\"]].values\n",
        "   return boxes_array\n",
        "\n",
        "class RaccoonDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, root, data_file, transforms=None):\n",
        "    self.root = root\n",
        "    self.transforms = transforms\n",
        "    self.imgs = sorted(os.listdir(os.path.join(root, \"images\")))\n",
        "    self.path_to_data_file = data_file\n",
        "  def __getitem__(self, idx):\n",
        "    # load images and bounding boxes\n",
        "    img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    box_list = parse_one_annot(self.path_to_data_file, self.imgs[idx])\n",
        "    boxes = torch.as_tensor(box_list, dtype=torch.float32)\n",
        "    num_objs = len(box_list)\n",
        "    # there is only one class\n",
        "    labels = torch.ones((num_objs,), dtype=torch.int64)\n",
        "    image_id = torch.tensor([idx])\n",
        "    area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:,\n",
        "    0])\n",
        "    # suppose all instances are not crowd\n",
        "    iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "    target = {}\n",
        "    target[\"boxes\"] = boxes\n",
        "    target[\"labels\"] = labels\n",
        "    target[\"image_id\"] = image_id\n",
        "    target[\"area\"] = area\n",
        "    target[\"iscrowd\"] = iscrowd\n",
        "    if self.transforms is not None:\n",
        "      img, target = self.transforms(img, target)\n",
        "    return img, target\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_w-BfREE_Hg"
      },
      "source": [
        "dataset = RaccoonDataset(root= \"/content/raccoon_dataset\",\n",
        "data_file = \"/content/raccoon_dataset/data/raccoon_labels.csv\")\n",
        "dataset.__getitem__(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xApwUST_FPGU"
      },
      "source": [
        "def get_model(num_classes):\n",
        "   # load an object detection model pre-trained on COCO\n",
        "   model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "   # get the number of input features for the classifier\n",
        "   in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "   # replace the pre-trained head with a new on\n",
        "   model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "   \n",
        "   return model\n",
        "\n",
        "def get_transform(train):\n",
        "   transforms = []\n",
        "   # converts the image, a PIL image, into a PyTorch Tensor\n",
        "   transforms.append(T.ToTensor())\n",
        "   if train:\n",
        "      # during training, randomly flip the training images\n",
        "      # and ground-truth for data augmentation\n",
        "      transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "   return T.Compose(transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmgvONg9F5pr",
        "outputId": "415b11d8-cc6b-406c-db37-0fc37e81afa3"
      },
      "source": [
        "# use our dataset and defined transformations\n",
        "dataset = RaccoonDataset(root= \"/content/raccoon_dataset\", data_file= \"content/raccoon_dataset/data/raccoon_labels.csv\",transforms = get_transform(train=True))\n",
        "dataset_test = RaccoonDataset(root= \"content/raccoon_dataset\", data_file= \"content/raccoon_dataset/data/raccoon_labels.csv\", transforms = get_transform(train=False))\n",
        "# split the dataset in train and test set\n",
        "torch.manual_seed(1)\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "dataset = torch.utils.data.Subset(dataset, indices[:-40])\n",
        "dataset_test = torch.utils.data.Subset(dataset_test, indices[-40:])\n",
        "# define training and validation data loaders\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "              dataset, batch_size=2, shuffle=True, num_workers=4,\n",
        "              collate_fn=utils.collate_fn)\n",
        "data_loader_test = torch.utils.data.DataLoader(\n",
        "         dataset_test, batch_size=1, shuffle=False, num_workers=4,\n",
        "         collate_fn=utils.collate_fn)\n",
        "print(\"We have: {} examples, {} are training and {} testing\".format(len(indices), len(dataset), len(dataset_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have: 200 examples, 160 are training and 40 testing\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YVsJYOsGGjB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e6ee742-9f2a-405d-a677-d974590f6009"
      },
      "source": [
        "torch.cuda.is_available()\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# our dataset has two classes only - raccoon and not racoon\n",
        "num_classes = 2\n",
        "# get the model using our helper function\n",
        "model = get_model(num_classes)\n",
        "# move model to the right device\n",
        "model.to(device)\n",
        "# construct an optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005,\n",
        "                            momentum=0.9, weight_decay=0.0005)\n",
        "# and a learning rate scheduler which decreases the learning rate by # 10x every 3 epochs\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                               step_size=3,\n",
        "                                               gamma=0.1)\n",
        "\n",
        "# let's train it for 10 epochs\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "   # train for one epoch, printing every 10 iterations\n",
        "   train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
        "    # update the learning rate\n",
        "   lr_scheduler.step()\n",
        "   # evaluate on the test dataset\n",
        "   evaluate(model, data_loader_test, device=device)\n",
        "\n",
        "os.mkdir(\"content/pytorch-object-detection/raccoon/\")\n",
        "torch.save(model.state_dict(), \"content/pytorch object detection/raccoon/model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [0]  [ 0/80]  eta: 0:54:54  lr: 0.000068  loss: 0.8298 (0.8298)  loss_classifier: 0.6909 (0.6909)  loss_box_reg: 0.1348 (0.1348)  loss_objectness: 0.0022 (0.0022)  loss_rpn_box_reg: 0.0018 (0.0018)  time: 41.1822  data: 0.5112\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}